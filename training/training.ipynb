{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"E5BAf-T83HQ5","colab_type":"code","outputId":"3c243dfa-fc3b-47e4-9ffa-95ffc90d4e02","executionInfo":{"status":"ok","timestamp":1576412454280,"user_tz":-330,"elapsed":13493,"user":{"displayName":"VAIBHAV GOYAL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDZ7drtZKozAMPR4tCYLATMeWyCXw7zarnF91-9=s64","userId":"09106313311714801771"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir(\"/content/gdrive/My Drive/BTP-SEM-7/vqa/training\")\n","import sys  \n","sys.path.append('../') "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bcgaj_q50ba9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":80},"outputId":"12a8312e-0bb0-44ec-b6ec-db0c0c35096a","executionInfo":{"status":"ok","timestamp":1576412462244,"user_tz":-330,"elapsed":5798,"user":{"displayName":"VAIBHAV GOYAL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDZ7drtZKozAMPR4tCYLATMeWyCXw7zarnF91-9=s64","userId":"09106313311714801771"}}},"source":["from keras.models import Sequential\n","import pandas as pd\n","from keras.optimizers import Adam,SGD\n","from keras.layers import concatenate, Multiply, Lambda, Embedding, Bidirectional, LSTM, GRU,Input, Add,Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n","from sklearn.metrics import log_loss\n","from keras.layers.normalization import BatchNormalization\n","from keras.models import load_model,Model\n","from keras.initializers import glorot_uniform\n","from keras.applications.vgg16 import VGG16\n","from keras.preprocessing.text import Tokenizer\n","from keras.optimizers import Adam, RMSprop\n","from keras.engine.topology import Layer\n","from keras import backend as K\n","from keras import initializers, regularizers, constraints\n","import cv2\n","import numpy as np\n","from keras.callbacks import Callback\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import f1_score\n","import glob\n","from sklearn import preprocessing\n","from keras.utils import to_categorical,Sequence\n","from model.model import vqaModelSimple,vqaModelBiLSTM,vqaModelSimpleFeatures,vqaModelBiLSTMFeatures\n","from keras.callbacks import ModelCheckpoint\n","import codecs\n","import h5py\n","from utils.utils import *\n","import zipfile"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"MaJxLIXPJBpo","colab_type":"code","outputId":"cde51a21-aa19-4b00-ad43-17d32ba00087","executionInfo":{"status":"ok","timestamp":1576327729795,"user_tz":-330,"elapsed":5635,"user":{"displayName":"VAIBHAV GOYAL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDZ7drtZKozAMPR4tCYLATMeWyCXw7zarnF91-9=s64","userId":"09106313311714801771"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sat Dec 14 12:48:47 2019       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pJHmuKT30s3A","colab_type":"code","colab":{}},"source":["df_train = pd.read_csv('../dataset/train_final.csv')\n","df_val = pd.read_csv(\"../dataset/val_final.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cLjmA6clnxN5","colab_type":"code","colab":{}},"source":["#Get 60 examples from each class\n","# df_new = pd.DataFrame(columns=df_train.columns)\n","# for label in arr_labels:\n","#   df_temp =  df_train[df_train['multiple_choice_answer']==label]\n","#   df_temp = df_temp.sample(60,random_state=42,replace=True)\n","#   df_new = df_new.append(df_temp)\n","# df_train = df_new"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6b7S-cHd0piQ","colab_type":"code","colab":{}},"source":["# df_train = df_train.loc[(df_train['multiple_choice_answer']=='yes') | (df_train['multiple_choice_answer']=='no')]\n","# df_val = df_val[(df_val['multiple_choice_answer']=='yes') | (df_val['multiple_choice_answer']=='no')]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uOaJHz5q19xu","colab_type":"code","colab":{}},"source":["labels = df_train['multiple_choice_answer']\n","arr_labels = labels.unique()\n","le = preprocessing.LabelEncoder()\n","le.fit(arr_labels)\n","y_train = le.transform(df_train['multiple_choice_answer'])\n","y_train = to_categorical(y_train)\n","y_val = le.transform(df_val['multiple_choice_answer'])\n","y_val = to_categorical(y_val)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xiBA3iT4qaLM","colab_type":"code","colab":{}},"source":["#Save label encoder\n","saveToPickle('../extras/', 'labelEncoder', le)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tUCygyiDlHQN","colab_type":"code","colab":{}},"source":["#Load train and validation features\n","train_features = readFromPickle('../image_features/', 'vgg16featuresTrain')\n","val_features = readFromPickle('../image_features/','vgg16featuresVal')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6VXyqsp77lfC","colab_type":"code","colab":{}},"source":["#To caluclate number of words in sentences\n","# count = df1['questions'].str.split().apply(len).value_counts()\n","# count "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ZbyklFo9zxQ","colab_type":"code","colab":{}},"source":["#Load word embeddings\n","embedding_index = loadWordEmbeddings('../dataset/glove.840B.300d.txt', embed_size = 300)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hq8yjhpAATfb","colab_type":"code","colab":{}},"source":["image_feature_dims = 4096\n","time_steps = 20\n","embed_size = 300\n","units = 256\n","num_classes = 1000\n","# dropout = 0.01\n","dropout = 0.2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LmAcSLir-jaT","colab_type":"code","outputId":"f6bf588b-9270-4012-dedf-8a91102389c3","executionInfo":{"status":"ok","timestamp":1576412563931,"user_tz":-330,"elapsed":6164,"user":{"displayName":"VAIBHAV GOYAL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDZ7drtZKozAMPR4tCYLATMeWyCXw7zarnF91-9=s64","userId":"09106313311714801771"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Creating Tokenizer\n","df_trainTemp = pd.read_csv('../dataset/train_final.csv')\n","tokenizer, word_index = createTokenizer(text = df_trainTemp['questions'], max_nb_words = 100000, oov_token = True)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["tokenizing input data...\n","dictionary size:  12487\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mBxInNfnrUWY","colab_type":"code","colab":{}},"source":["#Save Tokenizer\n","saveToPickle('../extras/', 'tokenizer', tokenizer)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SApS07NlJoLg","colab_type":"code","colab":{}},"source":["# embedding_matrix, words_not_found = createEmbeddingMatrix(word_index, embedding_index,embed_size)\n","print('preparing embedding matrix...')\n","words_not_found = []\n","nb_words = len(word_index)+1#vocabsize\n","embedding_matrix = np.zeros((nb_words, embed_size))\n","for word, i in word_index.items():\n","    \n","    embedding_vector = embedding_index.get(word)\n","    if (embedding_vector is not None):\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector\n","    else:\n","        print (word)\n","        words_not_found.append(word)\n","print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTvozvSUGGhH","colab_type":"code","colab":{}},"source":["#Save embedding matrix\n","saveToH5Py(embedding_matrix, '../dataset/' , 'embedding_matrix_glove')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NQJNVQbQGjYZ","colab_type":"code","colab":{}},"source":["#Read embedding matrix\n","embedding_matrix = readFromH5Py('../dataset/', 'embedding_matrix_glove')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0yxLkRrAsd5","colab_type":"code","colab":{}},"source":["#Create encoded and padded training data\n","X_train_sequences, X_train_questions = createEncodedPaddedText(tokenizer, df_train['questions'],time_steps=time_steps)\n","\n","#Create encoded and padded validation data\n","X_val_sequences, X_val_questions = createEncodedPaddedText(tokenizer, df_val['questions'],time_steps=time_steps)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CfZsIdE_aaf3","colab_type":"code","colab":{}},"source":["class Attention(Layer):\n","    def __init__(self, step_dim,\n","                 W_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","        \"\"\"\n","        Keras Layer that implements an Attention mechanism for temporal data.\n","        Supports Masking.\n","        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n","        # Input shape\n","            3D tensor with shape: `(samples, steps, features)`.\n","        # Output shape\n","            2D tensor with shape: `(samples, features)`.\n","        :param kwargs:\n","        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n","        The dimensions are inferred based on the output shape of the RNN.\n","        Example:\n","            model.add(LSTM(64, return_sequences=True))\n","            model.add(Attention())\n","        \"\"\"\n","        self.supports_masking = True\n","        #self.init = initializations.get('glorot_uniform')\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        self.step_dim = step_dim\n","        self.features_dim = 0\n","        super(Attention, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight((input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        self.features_dim = input_shape[-1]\n","\n","        if self.bias:\n","            self.b = self.add_weight((input_shape[1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","        else:\n","            self.b = None\n","\n","        self.built = True\n","\n","    def compute_mask(self, input, input_mask=None):\n","        # do not pass the mask to the next layers\n","        return None\n","\n","    def call(self, x, mask=None):\n","        # eij = K.dot(x, self.W) TF backend doesn't support it\n","\n","        # features_dim = self.W.shape[0]\n","        # step_dim = x._keras_shape[1]\n","\n","        features_dim = self.features_dim\n","        step_dim = self.step_dim\n","\n","        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n","\n","        if self.bias:\n","            eij += self.b\n","\n","        eij = K.tanh(eij)\n","\n","        a = K.exp(eij)\n","\n","        # apply mask after the exp. will be re-normalized next\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            a *= K.cast(mask, K.floatx())\n","\n","        # in some cases especially in the early stages of training the sum may be almost zero\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","    #print weigthted_input.shape\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        #return input_shape[0], input_shape[-1]\n","        return input_shape[0],  self.features_dim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUopB5WEaX2Y","colab_type":"code","colab":{}},"source":["def vqaModelBiLSTMAttFeatures(embedding_matrix, image_feature_dims=4096, trainable=False, num_classes=1000,embed_size=300, vocab_size=10000, time_steps=20, unit_length=512, dropout=0.5):\n","    #LSTM\n","    inputsLSTM = Input(shape=(time_steps,))\n","    x = Embedding(output_dim=embed_size, input_dim=vocab_size, weights=[embedding_matrix],input_length=time_steps, trainable=trainable)(inputsLSTM)\n","    # default merge_mode is concatenate others are mul,ave,sum\n","    y= Bidirectional(LSTM(unit_length, return_sequences=True), input_shape=(time_steps, 1), merge_mode='mul')(x)\n","    a= Bidirectional(LSTM(unit_length, return_sequences=True), input_shape=(time_steps, 1), merge_mode='sum')(y)\n","    att = Attention(time_steps)(a)\n","    modelLSTM = Model(inputs=inputsLSTM, outputs=att)\n","\n","    #Image MODEL\n","    inputsImage = Input(shape=(image_feature_dims,))\n","    outputsImage = Lambda(lambda  x: K.l2_normalize(x,axis=1))(inputsImage)\n","    modelVGG16New = Model(inputsImage, outputsImage)\n","\n","    merged = concatenate([modelLSTM.output, modelVGG16New.output])\n","    dense1 = Dense(1000, activation='tanh')(merged)\n","    dense1 = Dropout(dropout)(dense1)\n","    output =  Dense(num_classes, activation='softmax')(dense1)\n","    model = Model(inputs=[modelLSTM.input,modelVGG16New.input], outputs=output)\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qxzYoV-0X0kh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_K0EypcLIbwo","colab_type":"code","colab":{}},"source":["#MODEL 2\n","def vqaModelAttention(embedding_matrix, vdim = 2048, qdim=512, num_hid = 1024, image_feature_dims=2048, trainable=False, num_classes=1000,embed_size=300, vocab_size=10000, time_steps=14, unit_length=512, dropout=0.5, k=36):\n","    #FC model\n","    #inputFC = Input(shape=(vdim+qdim,))\n","    # denseFC = Dense(num_hid, activation='relu')(inputFC)\n","    # denseFC = Dense(1, activation='relu')(denseFC)\n","    #question\n","    inputsGRU = Input(shape=(time_steps,))\n","    x = Embedding(output_dim=embed_size, input_dim=vocab_size, weights=[embedding_matrix],input_length=time_steps, trainable=trainable)(inputsGRU)\n","    y= GRU(unit_length, return_sequences=False)(x)\n","    dense=Dense(512,activation='tanh')(y)\n","    y_new = Lambda(lambda x: K.expand_dims(x,axis=1))(dense)\n","\n","    # y_new = K.expand_dims(y,axis=1)\n","    expanded_qdim = Lambda(lambda x: K.repeat_elements(x,k,axis=1))(y_new)\n","    # expanded_qdim= K.repeat_elements(y_new,k,axis=1)\n","    #Image MODEL (assuming y1)\n","    \n","    y1 = Input(shape=(k,2048,))\n","\n","    concat = concatenate([expanded_qdim, y1],axis=2)\n","    denseFC = Dense(num_hid, activation='relu')(concat)\n","    denseFC = Dense(1, activation='softmax')(denseFC)\n","    #FCModel = Model(inputs=concat, outputs=denseFC)\n","\n","    afunc =  Dense(1, activation='softmax')(denseFC)\n","    afunc1 = Lambda(lambda x: K.repeat_elements(x,2048,axis=2))(afunc)\n","    # afunc1= K.repeat_elements(afunc,2048,axis=1)\n","    \n","    res= Multiply()([afunc1,y1])\n","    res = Lambda(lambda x: K.sum(res,axis=1))(res)\n","    # res= K.sum(res,axis=0)\n","    dense3= Dense(512, activation='tanh')(res)\n","    combined= Multiply()([dense, dense3])\n","    dense4= Dense(512, activation='tanh')(combined)\n","    dense5= Dense(512, activation='tanh')(dense4)\n","    dense6 = Dropout(dropout)(dense5)\n","    output =  Dense(num_classes, activation='softmax')(dense6)\n","\n","\n","    model = Model(inputs=[inputsGRU, y1], outputs=output)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GK20NXDvdYb8","colab_type":"code","colab":{}},"source":["#TESTING ATTENTION MODEL\n","vqa_model = vqaModelAttention(embedding_matrix=embedding_matrix, image_feature_dims =2048, trainable=False, num_classes=num_classes,embed_size=embed_size, vocab_size=len(word_index)+1, time_steps=time_steps, unit_length=512, dropout=dropout, k=36)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ukNCunFvxy5x","colab_type":"code","outputId":"cbdcef31-1fb0-4e37-d1a0-906a43d9f65c","executionInfo":{"status":"ok","timestamp":1576328619948,"user_tz":-330,"elapsed":2525,"user":{"displayName":"VAIBHAV GOYAL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDZ7drtZKozAMPR4tCYLATMeWyCXw7zarnF91-9=s64","userId":"09106313311714801771"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["vqa_model = vqaModelBiLSTMAttFeatures(embedding_matrix=embedding_matrix, image_feature_dims = image_feature_dims, trainable=False, num_classes=num_classes,embed_size=embed_size, vocab_size=len(word_index)+1, time_steps=time_steps, unit_length=units, dropout=dropout)\n","# vqa_model = vqaModelBiLSTMFeatures(embedding_matrix=embedding_matrix, image_feature_dims = image_feature_dims, trainable=False, num_classes=num_classes,embed_size=embed_size, vocab_size=len(word_index)+1, time_steps=time_steps, unit_length=units, dropout=dropout)\n","# vqa_model = vqaModelSimpleFeatures(embedding_matrix=embedding_matrix, image_feature_dims = image_feature_dims, trainable=False, num_classes=num_classes,embed_size=embed_size, vocab_size=len(word_index)+1, time_steps=time_steps, unit_length=units, dropout=dropout)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hieftu9ZlyPn","colab_type":"code","outputId":"9dd5a806-6ab6-42af-f283-420cd0a90885","executionInfo":{"status":"ok","timestamp":1576418981632,"user_tz":-330,"elapsed":1202,"user":{"displayName":"VAIBHAV GOYAL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDZ7drtZKozAMPR4tCYLATMeWyCXw7zarnF91-9=s64","userId":"09106313311714801771"}},"colab":{"base_uri":"https://localhost:8080/","height":884}},"source":["vqa_model.summary()"],"execution_count":112,"outputs":[{"output_type":"stream","text":["Model: \"model_27\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_91 (InputLayer)           (None, 20)           0                                            \n","__________________________________________________________________________________________________\n","embedding_42 (Embedding)        (None, 20, 300)      3746400     input_91[0][0]                   \n","__________________________________________________________________________________________________\n","gru_42 (GRU)                    (None, 512)          1248768     embedding_42[0][0]               \n","__________________________________________________________________________________________________\n","dense_123 (Dense)               (None, 512)          262656      gru_42[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_48 (Lambda)              (None, 1, 512)       0           dense_123[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_49 (Lambda)              (None, 36, 512)      0           lambda_48[0][0]                  \n","__________________________________________________________________________________________________\n","input_92 (InputLayer)           (None, 36, 2048)     0                                            \n","__________________________________________________________________________________________________\n","concatenate_38 (Concatenate)    (None, 36, 2560)     0           lambda_49[0][0]                  \n","                                                                 input_92[0][0]                   \n","__________________________________________________________________________________________________\n","dense_124 (Dense)               (None, 36, 1024)     2622464     concatenate_38[0][0]             \n","__________________________________________________________________________________________________\n","dense_125 (Dense)               (None, 36, 1)        1025        dense_124[0][0]                  \n","__________________________________________________________________________________________________\n","dense_126 (Dense)               (None, 36, 1)        2           dense_125[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_50 (Lambda)              (None, 36, 2048)     0           dense_126[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_14 (Multiply)          (None, 36, 2048)     0           lambda_50[0][0]                  \n","                                                                 input_92[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_51 (Lambda)              (None, 2048)         0           multiply_14[0][0]                \n","__________________________________________________________________________________________________\n","dense_127 (Dense)               (None, 512)          1049088     lambda_51[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_15 (Multiply)          (None, 512)          0           dense_123[0][0]                  \n","                                                                 dense_127[0][0]                  \n","__________________________________________________________________________________________________\n","dense_128 (Dense)               (None, 512)          262656      multiply_15[0][0]                \n","__________________________________________________________________________________________________\n","dense_129 (Dense)               (None, 512)          262656      dense_128[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 512)          0           dense_129[0][0]                  \n","__________________________________________________________________________________________________\n","dense_130 (Dense)               (None, 1000)         513000      dropout_2[0][0]                  \n","==================================================================================================\n","Total params: 9,968,715\n","Trainable params: 6,222,315\n","Non-trainable params: 3,746,400\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2LA01WHMr7fd","colab_type":"code","colab":{}},"source":["#Save model\n","# serialize model to JSON\n","model_json = vqa_model.to_json()\n","with open('../extras/vqaModelBiLSTMFeatures.json', \"w\") as json_file:\n","    json_file.write(model_json)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BZ0lRggS4p9T","colab_type":"code","colab":{}},"source":["#Skip files not present\n","class My_Custom_Generator(Sequence) :\n","  \n","  def __init__(self,questions, image_filenames, labels, batch_size,type_of_data, archive) :\n","    self.questions = questions\n","    self.image_filenames = image_filenames\n","    self.labels = labels\n","    self.batch_size = batch_size\n","    self.type_of_data = type_of_data\n","    self.archive = archive\n","    \n","    \n","  def __len__(self) :\n","    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n","  \n","  \n","  def __getitem__(self, idx) :\n","    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n","    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n","    \n","    questions_x = self.questions[idx * self.batch_size : (idx+1) * self.batch_size]\n","    questions = []\n","    images_x = []\n","    labels_y = []\n","    for counter, img in enumerate(batch_x):\n","      try:\n","        zeros = 12 - len(str(img))\n","        if(self.type_of_data=='val'):\n","          file_name = 'COCO_val2014_' + '0'*zeros + str(img) + '.jpg'\n","          imgData = self.archive.read('val2014/' + file_name)\n","          im = cv2.imdecode(np.frombuffer(imgData, np.uint8), 1)\n","  #         im = cv2.imread('../dataset/images/validation/val2014/' + file_name)\n","        if(self.type_of_data=='train'):\n","          file_name = 'COCO_train2014_' + '0'*zeros + str(img) + '.jpg'\n","          imgData = self.archive.read('train2014/' + file_name)\n","          im = cv2.imdecode(np.frombuffer(imgData, np.uint8), 1)\n","  #         im = cv2.imread('../dataset/images/train/train2014/' + file_name)\n","        im = cv2.resize(im, (224,224))\n","        im = im/255.0\n","        images_x.append(im)\n","        labels_y.append(batch_y[counter])\n","        questions.append(questions_x[counter])\n","#         print(counter)\n","      except:\n","        print(counter)\n","        continue\n","    \n","    return [np.asarray(questions), np.asarray(images_x)], np.asarray(labels_y)\n","#     return np.array([\n","#             resize(imread('/content/all_images/' + str(file_name)), (80, 80, 3))\n","#                for file_name in batch_x])/255.0, np.array(batch_y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"61VagZuycwX8","colab_type":"code","colab":{}},"source":["#For Image preloaded image features\n","class My_Custom_Generator_Features(Sequence) :\n","  \n","  def __init__(self,questions, image_filenames, labels, batch_size,dictionary) :\n","    self.questions = questions\n","    self.image_filenames = image_filenames\n","    self.labels = labels\n","    self.batch_size = batch_size\n","    self.dictionary = dictionary\n","    \n","    \n","  def __len__(self) :\n","    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n","  \n","  \n","  def __getitem__(self, idx) :\n","    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n","    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n","    \n","    questions_x = self.questions[idx * self.batch_size : (idx+1) * self.batch_size]\n","    images_x = []\n","    for counter, img in enumerate(batch_x):\n","      images_x.append(self.dictionary[img])\n","    \n","    return [np.asarray(questions_x), np.asarray(images_x)], np.asarray(batch_y)\n","#     return np.array([\n","#             resize(imread('/content/all_images/' + str(file_name)), (80, 80, 3))\n","#                for file_name in batch_x])/255.0, np.array(batch_y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CTtC7y5ul-u4","colab_type":"code","colab":{}},"source":["#PreLoaded Image Features\n","batch_size = 512\n","my_training_batch_generator = My_Custom_Generator_Features(X_train_questions, df_train['image_id'], y_train, batch_size, train_features)\n","my_validation_batch_generator = My_Custom_Generator_Features(X_val_questions, df_val['image_id'], y_val, batch_size, val_features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8uFExx7XsIi3","colab_type":"code","colab":{}},"source":["batch_size = 128\n","train_archive = zipfile.ZipFile('../../Dataset-Coco-V2/vqa_v2_images.zip','r')\n","val_archive = zipfile.ZipFile('../../Dataset-Coco-V2/vqa_v2_validation_images.zip','r')\n","my_training_batch_generator = My_Custom_Generator(X_train_questions, df_train['image_id'], y_train, batch_size, 'train',train_archive)\n","my_validation_batch_generator = My_Custom_Generator(X_val_questions, df_val['image_id'][:5120], y_val[:5120], batch_size, 'val',val_archive)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZfuFY_WLMEnO","outputId":"14a88cfe-3f5c-41ae-be3d-e20a9e49a9d7","executionInfo":{"status":"ok","timestamp":1570891614614,"user_tz":-330,"elapsed":1240,"user":{"displayName":"VAIBHAV GOYAL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDZ7drtZKozAMPR4tCYLATMeWyCXw7zarnF91-9=s64","userId":"09106313311714801771"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["optimizer = Adam(lr=0.001)\n","# optimizer = RMSprop()\n","vqa_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rGQJWOHTKV0Y","colab_type":"code","colab":{}},"source":["vqa_model.load_weights('../weights/best_weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gQNTdyPzynAI","colab_type":"code","outputId":"11b26b12-0bd1-4d59-96eb-8ed2d39bc7b5","executionInfo":{"status":"error","timestamp":1570631856849,"user_tz":-330,"elapsed":4024516,"user":{"displayName":"VAIBHAV GOYAL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDZ7drtZKozAMPR4tCYLATMeWyCXw7zarnF91-9=s64","userId":"09106313311714801771"}},"colab":{"base_uri":"https://localhost:8080/","height":177}},"source":["checkpoint = ModelCheckpoint('../weights/best_weights.h5', monitor='val_acc', verbose=1, save_best_only=True,save_weights_only=True, mode='max')\n","callbacks_list = [checkpoint]\n","vqa_model.fit_generator(generator=my_training_batch_generator,\n","                   epochs = 55,\n","                   verbose = 1,\n","                   validation_data = my_validation_batch_generator,\n","                   callbacks = callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Epoch 1/55\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yobzR7n0Cjrc","colab_type":"code","colab":{}},"source":["\n","vqa_model.save_weights('../weights/vqaModelBiLSTM_5epochs.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2IBsP681Ni8o","colab_type":"code","outputId":"0c3edb05-1020-41b7-8c7c-5ea134d1e0c5","executionInfo":{"status":"ok","timestamp":1570582917382,"user_tz":-330,"elapsed":2740,"user":{"displayName":"VAIBHAV GOYAL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDZ7drtZKozAMPR4tCYLATMeWyCXw7zarnF91-9=s64","userId":"09106313311714801771"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cntr=0\n","lst=val_archive.namelist()\n","for img in df_val['image_id'][:5000]:\n","  zeros = 12 - len(str(img))\n","  file_name = 'val2014/' +'COCO_val2014_' + '0'*zeros + str(img) + '.jpg'\n","  if(file_name not in lst):\n","    cntr=cntr+1\n","    \n","print(cntr)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]}]}