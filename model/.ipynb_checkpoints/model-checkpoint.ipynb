{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Embedding, Bidirectional, LSTM, Input, Add,Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.models import load_model,Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16Model(numClasses=1000):\n",
    "    model = VGG16(include_top=True, weights='imagenet', classes=numClasses)\n",
    "    ip = model.input\n",
    "    op = model.layers[-2].output\n",
    "    vgg16Model = Model(ip,op)\n",
    "    for layer in vgg16Model.layers:\n",
    "        layer.trainable = False\n",
    "    return vgg16Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstmModel(embedding_matrix, trainable, embed_size, vocab_size, time_steps, unit_length):\n",
    "    inputs = Input(shape=(time_steps,))\n",
    "    x = Embedding(output_dim=embed_size, input_dim=vocab_size, weights=[embedding_matrix],input_length=time_steps, trainable=trainable)(inputs)\n",
    "    #default merge_mode is concatenate others are mul,ave,sum\n",
    "    y= Bidirectional(LSTM(unit_length, return_sequences=True), input_shape=(time_steps, 1), merge_mode='mul')(x)\n",
    "    #print(\"y.shape\",y.shape)\n",
    "    a= Bidirectional(LSTM(unit_length, return_sequences=False), input_shape=(time_steps, 1), merge_mode='sum')(y)\n",
    "    model = Model(inputs=inputs, outputs=a)\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vqaModel(embedding_matrix, trainable=False, num_classes=1000,embed_size=100, vocab_size=10000, time_steps=20, unit_length=256):\n",
    "    encoded_question=vgg16Model(num_classes)\n",
    "    encoded_image=lstmModel(embedding_matrix, trainable, embed_size, vocab_size, time_steps, unit_length)\n",
    "\n",
    "    merged = keras.layers.concatenate([encoded_question.output, encoded_image.output])\n",
    "    output = Dense(num_classes, activation='softmax')(merged)\n",
    "    vqa_model = Model(inputs=[encoded_question.input, encoded_image.input], outputs=output)\n",
    "    return vqa_model\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
